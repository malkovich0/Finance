{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breathing-reality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:19:24.940711Z",
     "start_time": "2021-05-16T04:19:20.244435Z"
    }
   },
   "outputs": [],
   "source": [
    "import dart_fss as dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "driven-digit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:19:27.140268Z",
     "start_time": "2021-05-16T04:19:25.921998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f019243de247f120e3db654abec1d1ee6398eb72'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key = open('crtfc_key.txt',mode='r').readline()\n",
    "dart.set_api_key(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "consolidated-ownership",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:21:40.615882Z",
     "start_time": "2021-05-16T04:21:40.316340Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Union, List, Dict, Tuple, Pattern, Optional\n",
    "from collections import OrderedDict\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "\n",
    "from dart_fss.filings.reports import Report\n",
    "from dart_fss.filings import search as search_filings\n",
    "from dart_fss.utils import str_compare, str_unit_to_number_unit, str_insert_whitespace, is_notebook\n",
    "from dart_fss.errors.errors import NotFoundConsolidated, NoDataReceived\n",
    "from dart_fss.utils import str_to_regex, get_currency_str\n",
    "from dart_fss.fs.fs import FinancialStatement\n",
    "\n",
    "\n",
    "def str_to_float(text: str, unit: float) -> float:\n",
    "    \"\"\" 문자를 float 데이터로 변환\n",
    "    문자를 float 데이터로 변환, (1,000) 같은 경우 -1000 으로 변환\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        입력문자\n",
    "    unit: float\n",
    "        unit for table\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        변환된 숫자\n",
    "    \"\"\"\n",
    "    regex = re.compile(r'\\((-*\\d+)\\)|\\(-\\)(\\d+)')  # 음수 처리를 위한 정규식\n",
    "    regex_korean = re.compile(r'[ㄱ-힣]|[a-zA-Z]')\n",
    "    if isinstance(text, str):\n",
    "        try:\n",
    "            text = re.sub(r',|\\s+', '', text)\n",
    "            if regex_korean.search(text):\n",
    "                value = float(regex_korean.sub('', text))\n",
    "                # Value 값에 단위가 들어간 경우 unit으로 나누어 이후 계산에서 일괄적으로 곱해질 unit 값을 제거한다\n",
    "                if re.search('원', text):\n",
    "                    return value / unit\n",
    "                else:\n",
    "                    return value\n",
    "            if regex.search(text):\n",
    "                value = regex.search(text).group(1)\n",
    "                if value is None:\n",
    "                    value = regex.search(text).group(2)\n",
    "                return -float(value)\n",
    "            else:\n",
    "                return float(text)\n",
    "        except (ValueError, TypeError):\n",
    "            return 0.0\n",
    "    elif isinstance(text, (int, float)):\n",
    "        return float(text)\n",
    "    else:\n",
    "        raise ValueError('Invalid Value: {}'.format(text))\n",
    "\n",
    "\n",
    "def extract_date_from_header(header):\n",
    "    \"\"\" 재무제표 기간 추출을 위해 사용하는 method\"\"\"\n",
    "    # YYYY년 MM월 DD일 형태 검색\n",
    "    regex = re.compile(r'(\\d{4})[^0-9]*\\s*(\\d{1,2})[^0-9]*\\s*(\\d{1,2})')\n",
    "    # YYYY년 MM월 DD일 M'M'월 D'D'일 형태 검색\n",
    "    regex2 = re.compile(r'(\\d{4})[^0-9]*\\s*(\\d{1,2})[^0-9]*\\s*(\\d{1,2})[^0-9]*\\s*(\\d{1,2})[^0-9]*\\s*(\\d{1,2})')\n",
    "    date_info = []\n",
    "    td_list = header.find_all('td')\n",
    "    for td in td_list:\n",
    "        # Remove white text in tag\n",
    "        for tag in td.find_all(style=re.compile(r'color:#ffffff', re.IGNORECASE)):\n",
    "            tag.decompose()\n",
    "\n",
    "        searched = regex.findall(td.text)\n",
    "        searched2 = regex2.findall(td.text)\n",
    "        if len(searched) > 0:\n",
    "            f = searched[0]\n",
    "            if len(searched2) == 0:\n",
    "                # 오류 방지를 위해 Dummy 값 삽입\n",
    "                searched2 = [[9999, 99, 99, 99, 99]]\n",
    "            s = searched2[0]\n",
    "            # 만약 regex와 regex2의 첫번째 결과 값이 동일할때 regex2로 검색처리\n",
    "            # 제21(당)기 2018년 01월 01일부터 12월 31일 까지 형태 처리\n",
    "            if f[1] == s[1] and f[2] == s[2] and int(s[3]) < 13 and int(s[4]) < 32:\n",
    "                date = []\n",
    "\n",
    "                year = int(s[0])\n",
    "                month = int(s[1])\n",
    "                day = int(s[2])\n",
    "                date.append(datetime(year, month, day))\n",
    "\n",
    "                month = int(s[3])\n",
    "                day = int(s[4])\n",
    "                date.append(datetime(year, month, day))\n",
    "\n",
    "                if len(date) > 0:\n",
    "                    date_info.append(tuple(date))\n",
    "            else:\n",
    "                date = []\n",
    "                for d in searched:\n",
    "                    year = int(d[0])\n",
    "                    month = int(d[1])\n",
    "                    day = int(d[2])\n",
    "                    date.append(datetime(year, month, day))\n",
    "                if len(date) > 0:\n",
    "                    date_info.append(tuple(date))\n",
    "\n",
    "    return date_info\n",
    "\n",
    "\n",
    "def extract_unit_from_header(header):\n",
    "    \"\"\" html에서 unit을 추출하는 함수 \"\"\"\n",
    "    unit_regex = re.compile(r'\\(단위\\s*?:\\s*(.*)\\)')\n",
    "    td_list = header.find_all('td')\n",
    "    for td in td_list:\n",
    "        searched = unit_regex.search(td.text)\n",
    "        if searched:\n",
    "            return searched.group(1)\n",
    "\n",
    "    return '원'\n",
    "\n",
    "\n",
    "def convert_thead_into_columns(fs_tp: str, fs_table: dict, separate: bool = False,\n",
    "                               lang: str = 'ko'):\n",
    "    \"\"\" thead에서 DataFrame의 columns을 추출하는 Method\"\"\"\n",
    "    def column_ko_to_en(ko):\n",
    "        ko_to_en = {\n",
    "            '과목': 'label_ko',\n",
    "            '주석': 'comment'\n",
    "        }\n",
    "        en = ko_to_en.get(ko)\n",
    "        return en if en else ko\n",
    "\n",
    "    thead = fs_table['table'].thead\n",
    "\n",
    "    if thead is None:\n",
    "        tt = fs_table['table'].tbody.tr.extract()\n",
    "        thead = BeautifulSoup('<thead></thead>', 'html.parser')\n",
    "        thead.thead.append(tt)\n",
    "        for td in thead.tr.find_all('td'):\n",
    "            td.name = 'th'\n",
    "    th_colspan_list = [int(th.attrs.get('colspan', 1)) for th in thead.tr.find_all('th')]\n",
    "    date_info = extract_date_from_header(fs_table['header'])\n",
    "    # Regular Expression for title\n",
    "    regex = str_to_regex('과목 OR 주석')\n",
    "\n",
    "    fs_string = {\n",
    "        'bs': 'Statement of financial position',\n",
    "        'is': 'Income statement',\n",
    "        'cis': 'Statement of comprehensive income',\n",
    "        'cf': 'Statement of cash flows'\n",
    "    }\n",
    "\n",
    "    str_unit = extract_unit_from_header(fs_table['header'])\n",
    "    str_unit = get_currency_str(str_unit)\n",
    "    if str_unit:\n",
    "        for key in fs_string:\n",
    "            fs_string[key] = fs_string[key] + '(Unit: {})'.format(str_unit)\n",
    "\n",
    "    label = {\n",
    "        'ko': {\n",
    "            True: '별도재무제표',\n",
    "            False: '연결재무제표'\n",
    "        },\n",
    "        'en': {\n",
    "            True: 'Separate',\n",
    "            False: 'Consolidated'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 최대 Col\n",
    "    col_length = sum(th_colspan_list)\n",
    "    # 최대 Row\n",
    "    row_length = len(thead.find_all('tr'))\n",
    "    row_length = row_length + 1 if row_length == 1 else row_length\n",
    "    # row-sapn, col-span을 처리하기 위한 Matrix\n",
    "    columns_matrix = [[None for _y in range(col_length)] for _x in range(row_length)]\n",
    "    for idx, tr in enumerate(thead.find_all('tr')):\n",
    "        start_idx = 0\n",
    "        for ele_idx, element in enumerate(columns_matrix[idx]):\n",
    "            if element is None:\n",
    "                start_idx = ele_idx\n",
    "                break\n",
    "\n",
    "        for jdx, th in enumerate(tr.find_all('th')):\n",
    "            row_span = int(th.attrs.get('rowspan', 1))\n",
    "            col_span = int(th.attrs.get('colspan', 1))\n",
    "            text = re.sub(r'\\s+', '', th.text)\n",
    "            date_list = [datetime(1900, 1, 1)]\n",
    "            if idx == 0:\n",
    "                if jdx == 0:\n",
    "                    text = '과목'\n",
    "                elif regex.search(text) is None:\n",
    "                    if len(date_info) > 0:\n",
    "                        date_list = date_info.pop(0)\n",
    "                    else:\n",
    "                        date = '-'.join([date.strftime('%Y%m%d') for date in date_list])\n",
    "                        warnings_text = \"Date data length does not match table header.\"\\\n",
    "                                + \"So last date was set using last data({}). \".format(date)\n",
    "                        warnings.warn(warnings_text, RuntimeWarning)\n",
    "                    text = '-'.join([date.strftime('%Y%m%d') for date in date_list])\n",
    "\n",
    "            if regex.search(text):\n",
    "                row_span = 2\n",
    "\n",
    "            for mdx in range(row_span):\n",
    "                for ndx in range(col_span):\n",
    "                    new_text = text\n",
    "                    if mdx == 0 and regex.search(text):\n",
    "                        new_text = fs_string[fs_tp]\n",
    "                    columns_matrix[idx + mdx][start_idx + ndx] = new_text\n",
    "            start_idx = start_idx + ndx + 1\n",
    "\n",
    "    regex_3month = re.compile(r'3개월')\n",
    "    regex_total = str_to_regex(r'누적 OR 금액')\n",
    "\n",
    "    columns = []\n",
    "\n",
    "    for jdx in range(len(columns_matrix[0])):\n",
    "        column = []\n",
    "        sec_item = []\n",
    "        for idx in range(len(columns_matrix)):\n",
    "            item = columns_matrix[idx][jdx]\n",
    "            if idx == 0:\n",
    "                column.append(item)\n",
    "                continue\n",
    "            elif idx == 1 and (item is None or regex.search(item) is None):\n",
    "                sec_item.append(label[lang][separate])\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if item is None:\n",
    "                pass\n",
    "            elif str_compare(column[0], item):\n",
    "                continue\n",
    "            elif regex_3month.search(item):\n",
    "                # extract date info\n",
    "                date_info = [datetime.strptime(date_str, '%Y%m%d') for date_str in column[0].split('-')]\n",
    "\n",
    "                # calculating start_dt\n",
    "                delta = relativedelta(months=3)\n",
    "                start_dt = date_info[1] - delta\n",
    "                start_dt = start_dt.replace(day=1)\n",
    "\n",
    "                end_dt = date_info[1]\n",
    "                column[0] = '-'.join([date.strftime('%Y%m%d') for date in [start_dt, end_dt]])\n",
    "            elif regex_total.search(item):\n",
    "                pass\n",
    "            else:\n",
    "                sec_item.append(column_ko_to_en(item))\n",
    "        if sec_item[0] in ['label_ko', 'comment']:\n",
    "            column.append(sec_item[0])\n",
    "        else:\n",
    "            column.append(tuple(sec_item))\n",
    "        columns.append(column)\n",
    "    return columns\n",
    "\n",
    "\n",
    "def convert_tbody_to_dataframe(columns: list, fs_table: dict):\n",
    "    \"\"\" Html의 tbody를 DataFrame으로 변환하는 함수\"\"\"\n",
    "    column_matrix = OrderedDict()\n",
    "    for idx, column in enumerate(columns):\n",
    "        key = tuple(column)\n",
    "        if column_matrix.get(key):\n",
    "            column_matrix[key].append(idx)\n",
    "        else:\n",
    "            column_matrix[key] = []\n",
    "            column_matrix[key].append(idx)\n",
    "    deduplicated = [key for key in column_matrix]\n",
    "\n",
    "    df_columns = pd.MultiIndex.from_tuples(deduplicated)\n",
    "    df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "    tbody = fs_table['table'].tbody\n",
    "    regex = str_to_regex('label_ko OR comment')\n",
    "    str_unit = extract_unit_from_header(fs_table['header'])\n",
    "    unit = str_unit_to_number_unit(str_unit)\n",
    "    unit_regex = re.compile(r'\\(단위\\s*?:\\s*([a-zA-Zㄱ-힣])\\)')\n",
    "\n",
    "    # br 태그에 의해 구분되는 경우 처리하기 위한 함수\n",
    "    def get_text_before_newline(tag):\n",
    "        br = tag.find('br')\n",
    "        if br is None:\n",
    "            # br 태그가 없을시 단순 반환\n",
    "            return tag.text\n",
    "        else:\n",
    "            text = ''\n",
    "            for x in br.previous_siblings:\n",
    "                text += str(x)\n",
    "            # br 태그로 구분되는 경우 첫번째 라인 텍스트만 반환\n",
    "            return BeautifulSoup(text, 'html.parser').text\n",
    "\n",
    "    for idx, tr in enumerate(tbody.find_all('tr')):\n",
    "        extracted = [re.sub(r'\\s+|=+', '', get_text_before_newline(td)) for td in tr.find_all('td')]\n",
    "        row = {key: 0 for key in deduplicated}\n",
    "        for key, index_list in column_matrix.items():\n",
    "            for index in index_list:\n",
    "                if len(extracted) <= index:\n",
    "                    row[key] = None\n",
    "                elif isinstance(key[1], str):\n",
    "                    row[key] = extracted[index]\n",
    "                elif regex.search(' '.join(key[1])):\n",
    "                    value = extracted[index]\n",
    "                    row[key] = value\n",
    "                else:\n",
    "                    value = str_to_float(extracted[index], unit)\n",
    "                    row[key] += value\n",
    "\n",
    "            if isinstance(row[key], float):\n",
    "                if abs(row[key]) < 1e-10:\n",
    "                    row[key] = ''\n",
    "                else:\n",
    "                    row[key] = row[key] * unit\n",
    "\n",
    "        ordered_list = []\n",
    "        for column in df_columns.tolist():\n",
    "            ordered_list.append(row.get(column, None))\n",
    "\n",
    "        row_unit = unit_regex.search(ordered_list[0])\n",
    "        if row_unit:\n",
    "            row_unit = str_unit_to_number_unit(row_unit.group(1))\n",
    "            for jdx, value in enumerate(ordered_list):\n",
    "                if isinstance(value, str):\n",
    "                    pass\n",
    "                else:\n",
    "                    ordered_list[jdx] = ordered_list[jdx] / unit * row_unit\n",
    "\n",
    "        df.loc[idx] = ordered_list\n",
    "    return df\n",
    "\n",
    "\n",
    "def seek_table(tables: List, includes: Pattern,\n",
    "               excludes: Union[Pattern, None] = None) -> Tuple[Union[str, None], Union[str, None], Union[str, None]]:\n",
    "    \"\"\" Table 검색 \"\"\"\n",
    "    # 날짜 검색을 위한 Regular Expression\n",
    "    regex = re.compile(r'\\d{4}(.*?)\\d{1,2}(.*?)\\d{1,2}')\n",
    "\n",
    "    # Header Tag 가 아닌 경우 저장\n",
    "    not_headers = []\n",
    "\n",
    "    # Minimum Row Number\n",
    "    MIN_ROW_NUMBER = 4\n",
    "\n",
    "    for table in tables:\n",
    "        # Table 의 Row 가 4개 이하인 경우 재무제표 테이블이 아닌것으로 판정\n",
    "        rows = table.find_all('tr')\n",
    "        if len(rows) < MIN_ROW_NUMBER:\n",
    "            continue\n",
    "\n",
    "        for tag in table.previous_siblings:\n",
    "            # tag 가 tables 에 있으면 검색 종료\n",
    "            if tag in tables:\n",
    "                break\n",
    "            # tag 가 Tag Object 인 경우에만 검색 진행\n",
    "            if isinstance(tag, Tag):\n",
    "                # title 검색\n",
    "                children = tag.find_all(text=includes)\n",
    "                if len(children) == 0:  # 부국증권도 사업보고서 검색 안되던 문제 해결을 위한 코드(#66)\n",
    "                    if includes.search(tag.text) is not None:\n",
    "                        children = [tag.text]\n",
    "                for child in children:\n",
    "                    title = child\n",
    "                    if title:\n",
    "                        title = re.sub(r'\\s+', '', title)\n",
    "                        # 만약 타이틀에 제외될 단어 포함시 Pass\n",
    "                        if excludes and excludes.search(title):\n",
    "                            not_headers.append(tag)\n",
    "                            continue\n",
    "\n",
    "                        # 타이틀이 너무 길때 Pass\n",
    "                        # len(title) > 12 일때 일부 회사(메리츠화재)에서 연결포괄손익계산서 검색이 안되는 문제가 발생\n",
    "                        if len(title) > 13:\n",
    "                            not_headers.append(tag)\n",
    "                            continue\n",
    "\n",
    "                        headers = table.find_all_previous('table', class_='nb')\n",
    "                        for header in headers:\n",
    "\n",
    "                            # Header 가 None 이거나 not_headers 에 포함된 경우 Pass\n",
    "                            if header is None or header in not_headers:\n",
    "                                continue\n",
    "\n",
    "                            # Row 가 2개 이하인 경우 Pass\n",
    "                            tr_list = header.find_all('tr')\n",
    "                            if len(tr_list) < 2:\n",
    "                                continue\n",
    "\n",
    "                            # 검색된 날짜가 한개도 없을 경우 Pass\n",
    "                            datetime_cnt = 0\n",
    "                            for tr in tr_list:\n",
    "                                if regex.search(tr.text):\n",
    "                                    datetime_cnt += 1\n",
    "\n",
    "                            if datetime_cnt == 0:\n",
    "                                continue\n",
    "\n",
    "                            return title, header, table\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def search_fs_table(tables: List, fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'),\n",
    "                    separate: bool = False) -> Dict[str, dict]:\n",
    "    \"\"\"\n",
    "    페이지의 재무제표 테이블을 검색하는 함수\n",
    "    Parameters\n",
    "    ----------\n",
    "    tables: list of ResultSet\n",
    "        page 내부에서 검색된 모든 Tables\n",
    "    fs_tp: tuple of str\n",
    "        'bs' 재무상태표, 'is' 손익계산서, 'cis' 포괄손익계산서, 'cf' 현금흐름표\n",
    "    separate: bool\n",
    "        개별 재무제표 여부\n",
    "    Returns\n",
    "    -------\n",
    "    dict of {str : dict }\n",
    "        검색된 재무제표 결과\n",
    "    \"\"\"\n",
    "    fs_table = OrderedDict()\n",
    "\n",
    "    # 순서대로 검색 (순서 변경 금지)\n",
    "    queryset = {\n",
    "        'bs': str_insert_whitespace('재무상태표') + ' OR ' + str_insert_whitespace('대차대조표'),\n",
    "        'is': str_insert_whitespace('손익계산서'),\n",
    "        'cis': str_insert_whitespace('포괄손익계산서'),\n",
    "        'cf': str_insert_whitespace('현금흐름표'),\n",
    "    }\n",
    "\n",
    "    for key, query in queryset.items():\n",
    "        if key not in fs_tp:\n",
    "            continue\n",
    "\n",
    "        # 연결재무제표 검색시 사용할 query 구문\n",
    "        excludes = None\n",
    "        if not separate:\n",
    "            query = query + ' AND ' + str_insert_whitespace('연결')\n",
    "        else:\n",
    "            excludes = str_insert_whitespace('연결')\n",
    "\n",
    "        if key == 'is':\n",
    "            if excludes:\n",
    "                excludes += ' OR ' + str_insert_whitespace('포괄')\n",
    "            else:\n",
    "                excludes = str_insert_whitespace('포괄')\n",
    "\n",
    "        if excludes:\n",
    "            excludes = str_to_regex(excludes)\n",
    "\n",
    "        regex = str_to_regex(query)\n",
    "        title, header, tb = seek_table(tables=tables, includes=regex, excludes=excludes)\n",
    "        fs_table[key] = {'title': title, 'header': header, 'table': tb}\n",
    "    return fs_table\n",
    "\n",
    "\n",
    "def extract_fs_table(fs_table, fs_tp, separate: bool = False, lang: str = 'ko'):\n",
    "    results = OrderedDict()\n",
    "    for tp, table in fs_table.items():\n",
    "        if tp in fs_tp:\n",
    "            if table['table']:\n",
    "                columns = convert_thead_into_columns(fs_tp=tp, fs_table=table, separate=separate, lang=lang)\n",
    "                df = convert_tbody_to_dataframe(columns=columns, fs_table=table)\n",
    "            else:\n",
    "                df = None\n",
    "            results[tp] = df\n",
    "    return results\n",
    "\n",
    "\n",
    "def report_find_all(report: Report, query: dict, fs_tp: Tuple[str], separate: bool) -> Tuple[int, Dict[str, Dict]]:\n",
    "    \"\"\"\n",
    "    Report의 Page 중 Query 조건에 맞는 페이지 검색후 모든 재무제표 Table 추출\n",
    "    Parameters\n",
    "    ----------\n",
    "    report: Report\n",
    "        Report\n",
    "    query: dict\n",
    "        검색 조건\n",
    "    fs_tp:  tuple of str\n",
    "        검색할 재무제표 타입\n",
    "    separate: bool\n",
    "        개별 재무제표 여부\n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    fs_table = None\n",
    "    searched_end = False\n",
    "    searched = report.find_all(**query)\n",
    "\n",
    "    for key in searched:\n",
    "        for page in searched[key]:\n",
    "            non_break_space = u'\\xa0'\n",
    "            html = page.html.replace(non_break_space, ' ')\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            tables = soup.find_all('table', border='1')\n",
    "            fs_table = search_fs_table(tables=tables, fs_tp=fs_tp, separate=separate)\n",
    "            count = sum([fs_table[fs_tp]['table'] is not None for fs_tp in fs_table])\n",
    "            if count > 0:\n",
    "                searched_end = True\n",
    "                break\n",
    "        if searched_end:\n",
    "            break\n",
    "    return count, fs_table\n",
    "\n",
    "\n",
    "def analyze_html(report: Report, fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'),\n",
    "                 lang: str = 'ko', separate: bool = False) -> Union[Dict[str, DataFrame], None]:\n",
    "    \"\"\"\n",
    "    보고서의 HTML을 이용하여 재무제표를 추출하는 Method\n",
    "    Parameters\n",
    "    ----------\n",
    "    report: Report\n",
    "        리포트\n",
    "    fs_tp: tuple of str\n",
    "        'bs' 재무상태표, 'is' 손익계산서, 'cis' 포괄손익계산서, 'cf' 현금흐름표\n",
    "    lang: str\n",
    "        'ko': 한글 / 'en' 영문\n",
    "    separate: bool\n",
    "        개별 재무제표 여부\n",
    "    Returns\n",
    "    -------\n",
    "    dict of {str: DataFrame}\n",
    "        재무제표\n",
    "    \"\"\"\n",
    "    query = {\n",
    "        'includes': r'재무제표 OR 감사보고서',\n",
    "        'excludes': r'주석 OR 결합 OR 의견 OR 수정 OR 검토보고서',\n",
    "        'scope': ['attached_reports', 'pages'],\n",
    "        'options': {'title': True}  # 첨부보고서 및 연결보고서의 title 까지 검색\n",
    "    }\n",
    "\n",
    "    if separate:\n",
    "        query['excludes'] += ' OR 연결'\n",
    "    else:\n",
    "        query['includes'] += ' AND 연결'\n",
    "\n",
    "    count, fs_table = report_find_all(report, query, fs_tp, separate)\n",
    "\n",
    "    # 검색결과가 없을시 재검색, 검색 키워드 변경\n",
    "    if count == 0:\n",
    "        query = {\n",
    "            'includes': r'재무제표 OR 명세서',\n",
    "            'excludes': r'주석 OR 결합 OR 의견 OR 수정 OR 검토보고서',\n",
    "            'scope': ['attached_reports', 'pages']\n",
    "        }\n",
    "        count, fs_table = report_find_all(report, query, fs_tp, separate)\n",
    "\n",
    "    # 수정된 검색어의 경우에도 검색결과가 없을시, None 반환\n",
    "    if count == 0:\n",
    "        return None\n",
    "\n",
    "    extract_results = extract_fs_table(fs_table=fs_table, fs_tp=fs_tp, separate=separate, lang=lang)\n",
    "    return extract_results\n",
    "\n",
    "\n",
    "def find_all_columns(df: DataFrame, query: str) -> pd.Index:\n",
    "    \"\"\"\n",
    "    DataFrame의 column을 검색어를 통해 검색하는 함수\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        검색할 DataFrame\n",
    "    query: str\n",
    "        검색어\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of str\n",
    "        검색된 DataFrame의 column\n",
    "    \"\"\"\n",
    "    regex = str_to_regex(query)\n",
    "    if df is None:\n",
    "        return []\n",
    "    columns = df.columns.tolist()\n",
    "\n",
    "    results = []\n",
    "    for column in columns:\n",
    "        for item in column:\n",
    "            if isinstance(item, str) and regex.search(item):\n",
    "                results.append(column)\n",
    "            else:\n",
    "                if regex.search(' '.join(item)):\n",
    "                    results.append(column)\n",
    "    if len(results) > 0:\n",
    "        results = pd.MultiIndex.from_tuples(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_account_title(title):\n",
    "    title = title.split('.')\n",
    "    if len(title) == 1:\n",
    "        title = title[0]\n",
    "    elif len(title) > 1:\n",
    "        title = ''.join(title[1:])\n",
    "    title = re.sub(r'\\[.*?\\]|\\(.*?\\)|<.*?>|[^가-힣|a-z|A-Z]', '', title)\n",
    "    title = re.sub(r'\\s+', '', title)\n",
    "    return title\n",
    "\n",
    "\n",
    "def compare_df_and_ndf_label_and_concept(column: Tuple[Union[str, Tuple[str]]],\n",
    "                                         df: DataFrame, ndf: DataFrame, ldf: DataFrame,\n",
    "                                         ndata: List[Union[float, str, None]],\n",
    "                                         nlabels: List[str]) -> Tuple[List[Union[float, str]], List[str]]:\n",
    "    \"\"\"\n",
    "    Labels 을 시용하여 데이터를 검색하는 함수\n",
    "    Parameters\n",
    "    ----------\n",
    "    column: tuple\n",
    "        추가할 column Name\n",
    "    df: dict of { str: DataFrame }\n",
    "        데이터를 추가할 DataFrame\n",
    "    ndf: dict of { str: DataFrame }\n",
    "        데이터를 검색할 DataFrame\n",
    "    ldf: dict of { str: DataFrame }\n",
    "        Label DataFrame\n",
    "    ndata: list of float\n",
    "        추가할 column의 데이터 리스트\n",
    "    nlabels: list of str\n",
    "        추가할 column의 label 리스트\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of list\n",
    "        추가할 column의 데이터 리스트, 추가할 column의 label 리스트\n",
    "    \"\"\"\n",
    "    label_none_data = []\n",
    "    df_label_column = find_all_columns(df, 'label_ko')[0]\n",
    "    ndf_label_column = find_all_columns(ndf, 'label_ko')[0]\n",
    "\n",
    "    concept_none_data = {}\n",
    "    df_concept_column = find_all_columns(df, 'concept_id')\n",
    "    ndf_concept_column = find_all_columns(ndf, 'concept_id')\n",
    "\n",
    "    # concept_id 컬럼이 존재하는지 여부 조사\n",
    "    concept_exist = len(df_concept_column) * len(ndf_concept_column) != 0\n",
    "    if concept_exist:\n",
    "        df_concept_column = df_concept_column[0]\n",
    "        ndf_concept_column = ndf_concept_column[0]\n",
    "\n",
    "    en_none_data = {}\n",
    "    df_en_column = find_all_columns(df, 'label_en')\n",
    "    ndf_en_column = find_all_columns(ndf, 'label_en')\n",
    "\n",
    "    # label_en 컬럼이 존재하는지 여부 조사\n",
    "    en_exist = len(df_en_column) * len(ndf_en_column) != 0\n",
    "    if en_exist:\n",
    "        df_en_column = df_en_column[0]\n",
    "        ndf_en_column = ndf_en_column[0]\n",
    "\n",
    "    for idx, value in enumerate(ndata):\n",
    "        if isinstance(value, str):\n",
    "            # 이전에 검색된 데이터가 문자인 경우 pass\n",
    "            pass\n",
    "        elif value is None:\n",
    "            # 이전에 검색된 데이터가 없는 경우 pass\n",
    "            pass\n",
    "        elif math.isnan(value):\n",
    "            # 이전에 검색된 데이터가 유효한 값이 아닌 경우 pass\n",
    "            pass\n",
    "        else:\n",
    "            # 올바른 값이 경우 검색 X\n",
    "            continue\n",
    "\n",
    "        # label 추출\n",
    "        label = df[df_label_column].iloc[idx]\n",
    "        label = re.sub(r'\\s+', '', label)\n",
    "        label = extract_account_title(label)\n",
    "        label_set = set(ldf.iloc[idx])\n",
    "        label_set.add(label)\n",
    "        # (index, label_set) 리스트 생성\n",
    "        label_none_data.append((idx, label_set))\n",
    "\n",
    "        # concept_id가 존재하는 경우 concept_id도 추가로 검색\n",
    "        if concept_exist:\n",
    "            concept = df[df_concept_column].iloc[idx]\n",
    "            concept_none_data[concept] = idx\n",
    "\n",
    "        # label_en가 존재하는 경우 label_en도 추가로 검색\n",
    "        if en_exist:\n",
    "            en = df[df_en_column].iloc[idx]\n",
    "            en_none_data[en] = idx\n",
    "\n",
    "    # 기존 Dataframe index 중 사용된 결과 값 리스트\n",
    "    used = []\n",
    "\n",
    "    for idx in range(len(ndf)):\n",
    "        # 검색된 값\n",
    "        value_found = None\n",
    "        # 검색된 기존 Dataframe 의 index\n",
    "        index_found = None\n",
    "\n",
    "        # 검색할 label 명\n",
    "        label = extract_account_title(ndf[ndf_label_column].iloc[idx])\n",
    "\n",
    "        if concept_exist:\n",
    "            # 추가할 Dataframe 의 concept_id\n",
    "            concept = ndf[ndf_concept_column].iloc[idx]\n",
    "            index_found = concept_none_data.get(concept)\n",
    "            if index_found in used:\n",
    "                continue\n",
    "            elif index_found is not None:\n",
    "                value_found = ndf[column].iloc[idx]\n",
    "\n",
    "        if index_found is None:\n",
    "            if en_exist:\n",
    "                en = ndf[ndf_en_column].iloc[idx]\n",
    "                index_found = en_none_data.get(en)\n",
    "                if index_found in used:\n",
    "                    continue\n",
    "                elif index_found is not None:\n",
    "                    value_found = ndf[column].iloc[idx]\n",
    "\n",
    "        if index_found is None:\n",
    "            for index, label_set in label_none_data:\n",
    "                if index in used:\n",
    "                    continue\n",
    "                if label in label_set:\n",
    "                    value_found = ndf[column].iloc[idx]\n",
    "                    index_found = index\n",
    "                    break\n",
    "\n",
    "        if index_found is None:\n",
    "            pass\n",
    "        elif isinstance(index_found, int):\n",
    "            used.append(index_found)\n",
    "            ndata[index_found] = value_found\n",
    "            nlabels[index_found] = label\n",
    "\n",
    "    return ndata, nlabels\n",
    "\n",
    "\n",
    "def compare_df_and_ndf_value(column: pd.Index,\n",
    "                             df: DataFrame, ndf: DataFrame,\n",
    "                             ndata: List[Union[float, str, None]],\n",
    "                             nlabels: List[str]) -> Tuple[List[Union[float, str]], List[str]]:\n",
    "    \"\"\"\n",
    "    중복된 데이터의 값을 비교하여 데이터 값을 추출하는 함수\n",
    "    Parameters\n",
    "    ----------\n",
    "    column: tuple\n",
    "        추가할 column Name\n",
    "    df: dict of { str: DataFrame }\n",
    "        데이터를 추가할 DataFrame\n",
    "    ndf: dict of { str: DataFrame }\n",
    "        데이터를 검색할 DataFrame\n",
    "    ndata: list of float\n",
    "        추가할 column의 데이터 리스트\n",
    "    nlabels: list of str\n",
    "        추가할 column의 label 리스트\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of list\n",
    "        추가할 column의 데이터 리스트, 추가할 column의 label 리스트\n",
    "    \"\"\"\n",
    "    _, df_columns = split_columns_concept_data(df.columns)\n",
    "    _, ndf_columns = split_columns_concept_data(ndf.columns)\n",
    "\n",
    "    overlap = set(df_columns).intersection(set(ndf_columns))\n",
    "    nko_column = find_all_columns(ndf, r'label_ko')\n",
    "\n",
    "    index_used = []\n",
    "    for idx in range(len(df)):\n",
    "        nvalue = None\n",
    "        nlabel = ''\n",
    "        for col in overlap:\n",
    "            value = df[col].iloc[idx]\n",
    "            if isinstance(value, str):\n",
    "                pass\n",
    "            elif value is None:\n",
    "                pass\n",
    "            elif math.isnan(value):\n",
    "                pass\n",
    "            else:\n",
    "                sign = 1\n",
    "                # Ref와 일치하는 값을 가지는 row index 찾기\n",
    "                w = ndf[ndf[col] == value].dropna(axis=1, how='all').dropna(how='all')\n",
    "                # 만약 찾지 못하는 경우 Ref의 값의 음수와 동일한 값을 가지는 row index 찾기\n",
    "                if len(w) == 0:\n",
    "                    sign = -1\n",
    "                    w = ndf[ndf[col] == -value].dropna(axis=1, how='all').dropna(how='all')\n",
    "\n",
    "                found = False\n",
    "                if len(w) > 0:\n",
    "                    for index in w.index.values:\n",
    "                        if index not in index_used:\n",
    "                            nvalue = sign * ndf[column].iloc[index]\n",
    "                            nlabel = ndf[nko_column].iloc[index][0]\n",
    "                            nlabel = extract_account_title(nlabel)\n",
    "                            index_used.append(index)\n",
    "                            found = True\n",
    "                            break\n",
    "                if found:\n",
    "                    break\n",
    "        if nvalue and math.isnan(nvalue):\n",
    "            nvalue = None\n",
    "\n",
    "        ndata[idx] = nvalue\n",
    "        nlabels[idx] = nlabel\n",
    "    return ndata, nlabels\n",
    "\n",
    "\n",
    "additional_comparison_function = [compare_df_and_ndf_label_and_concept]\n",
    "\n",
    "\n",
    "def init_label(fs_df: Dict[str, DataFrame],\n",
    "               fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'),\n",
    "               label_df: Dict[str, DataFrame] = None):\n",
    "    \"\"\" 각각의 타입에 따라 추출된 Label들을 담고 있는 Dataframe 초기화\n",
    "    Parameters\n",
    "    ----------\n",
    "    fs_df: dict of {str: DataFrame}\n",
    "        추출된 재무제표\n",
    "    fs_tp: tuple of str, optional\n",
    "        'bs' 재무상태표, 'is' 손익계산서, 'cis' 포괄손익계산서, 'cf' 현금흐름표\n",
    "    label_df: dict of {str: DataFrame}\n",
    "        초기화할 label_df\n",
    "    Returns\n",
    "    -------\n",
    "    dict of {str : DataFrame}\n",
    "        초기화된 label_df\n",
    "    \"\"\"\n",
    "    if label_df is None:\n",
    "        label_df = {tp: None for tp in fs_tp}\n",
    "\n",
    "    for tp in fs_df:\n",
    "        if tp in fs_tp:\n",
    "            # 추가될 재무제표의 DataFrame\n",
    "            df = fs_df[tp]\n",
    "            if df is None:\n",
    "                continue\n",
    "            # label_df가 없을시 초기화\n",
    "            if label_df.get(tp) is None:\n",
    "                concept_column = find_all_columns(df, r'concept_id')\n",
    "                ko_column = find_all_columns(df, r'label_ko')\n",
    "                # Label_ko 가 없을시 Table 오류 이므로 None 처리\n",
    "                if len(ko_column) == 0:\n",
    "                    fs_df[tp] = None\n",
    "                    continue\n",
    "                else:\n",
    "                    ko_column = ko_column[0]\n",
    "                date_columns = find_all_columns(df, r'\\d{8}')\n",
    "\n",
    "                label_columns = []\n",
    "                if len(concept_column) == 1:\n",
    "                    label_columns.append(('default', 'concept_id',))\n",
    "                for column in date_columns:\n",
    "                    label_columns.append(column)\n",
    "                nlabel_columns = pd.MultiIndex.from_tuples(label_columns)\n",
    "                label_df[tp] = pd.DataFrame(columns=nlabel_columns)\n",
    "\n",
    "                if len(concept_column) == 1:\n",
    "                    label_df[tp][nlabel_columns[0]] = [extract_account_title(x) for x in list(df[concept_column[0]])]\n",
    "\n",
    "                for column in date_columns:\n",
    "                    label_df[tp][column] = list(df[ko_column])\n",
    "    return label_df\n",
    "\n",
    "\n",
    "def merge_fs(fs_df: Dict[str, DataFrame],\n",
    "             nfs_df: Dict[str, DataFrame],\n",
    "             label_df: Dict[str, DataFrame],\n",
    "             fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf')):\n",
    "    \"\"\"\n",
    "    재무제표 DataFrame과 Report의 데이터를 합쳐주는 Method\n",
    "    Parameters\n",
    "    ----------\n",
    "    fs_df: dict of {str: DataFrame}\n",
    "        데이터를 추가할 DataFrame\n",
    "    nfs_df: dict of {str: DataFrame}\n",
    "        새로운 데이터를 검색할 DataFrame\n",
    "    label_df: dict of {str: DataFrame}\n",
    "        재무제표 검색결과시 추출된 값의 Label\n",
    "    fs_tp: tuple of str, optional\n",
    "        'bs' 재무상태표, 'is' 손익계산서, 'cis' 포괄손익계산서, 'cf' 현금흐름표\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of dict of {str: DataFrame}\n",
    "        재무제표, 추출된 Label 리스트\n",
    "    \"\"\"\n",
    "    global additional_comparison_function\n",
    "\n",
    "    for tp in fs_df:\n",
    "        if tp in fs_tp:\n",
    "            # 추가될 재무제표의 DataFrame\n",
    "            df = fs_df[tp]\n",
    "\n",
    "            # 새로 추가할 재무제표\n",
    "            ndf = nfs_df[tp]\n",
    "\n",
    "            # 재무제표가 없을시 추가 검색 X\n",
    "            if df is None:\n",
    "                if ndf is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    fs_df[tp] = ndf.copy(deep=True)\n",
    "                    df = fs_df[tp]\n",
    "\n",
    "            # 검색된 재무제표가 없을시 추가 검색 X\n",
    "            if ndf is None:\n",
    "                continue\n",
    "\n",
    "            # label_df가 없을시 초기화\n",
    "            if label_df.get(tp) is None:\n",
    "                label_df = init_label(fs_df=fs_df, fs_tp=fs_tp, label_df=label_df)\n",
    "\n",
    "            _, df_columns = split_columns_concept_data(df.columns)\n",
    "            _, ndf_columns =  split_columns_concept_data(ndf.columns)\n",
    "            df_columns = set(df_columns.tolist())\n",
    "            ndf_columns = set(ndf_columns.tolist())\n",
    "\n",
    "            overlap = df_columns.intersection(ndf_columns)\n",
    "\n",
    "            date_regex = re.compile(r'\\d{8}')\n",
    "            diff = [x for x in (ndf_columns - overlap) if date_regex.search(x[0])]\n",
    "            diff.sort(key=lambda x: date_regex.findall(x[0])[0], reverse=True)\n",
    "\n",
    "            # Data가 동일할 경우 Continue\n",
    "            if len(diff) == 0:\n",
    "                continue\n",
    "\n",
    "            diff = pd.MultiIndex.from_tuples(diff)\n",
    "            overlap = list(overlap)\n",
    "\n",
    "            for column in diff:\n",
    "                ndata = [None for _ in range(len(df))]\n",
    "                nlabels = ['' for _ in range(len(df))]\n",
    "                if len(overlap) > 0:\n",
    "                    ndata, nlabels = compare_df_and_ndf_value(column, df, ndf, ndata, nlabels)\n",
    "\n",
    "                for compare_func in additional_comparison_function:\n",
    "                    ndata, nlabels = compare_func(column, df, ndf, label_df[tp], ndata, nlabels)\n",
    "\n",
    "                label_df[tp][column] = nlabels\n",
    "                fs_df[tp][column] = ndata\n",
    "\n",
    "    return fs_df, label_df\n",
    "\n",
    "\n",
    "def analyze_xbrl(report, fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'), separate: bool = False, lang: str = 'ko',\n",
    "                 show_abstract: bool = False, show_class: bool = True, show_depth: int = 10,\n",
    "                 show_concept: bool = True, separator: bool = True) -> Union[Dict[str, DataFrame], None]:\n",
    "    \"\"\"\n",
    "    Report의 xbrl 파일 분석을 통한 재무제표 추출\n",
    "    Parameters\n",
    "    ----------\n",
    "    report: Report\n",
    "        Report\n",
    "    fs_tp: tuple of str, optional\n",
    "        'bs' 재무상태표, 'is' 손익계산서, 'cis' 포괄손익계산서, 'cf' 현금흐름표\n",
    "    separate: bool, optional\n",
    "        개별재무제표 여부\n",
    "    lang: str, optional\n",
    "        'ko' 한글, 'en' 영문\n",
    "    show_abstract: bool, optional\n",
    "        Abstract 행 표시 여부\n",
    "    show_class: bool, optional\n",
    "        class 표시 여부\n",
    "    show_depth: int, optional\n",
    "        표시할 class 깊이\n",
    "    show_concept: bool, optional\n",
    "        concept_id 표시여부\n",
    "    separator: bool, optional\n",
    "        1000단위 구분자 표시 여부\n",
    "    Returns\n",
    "    -------\n",
    "    dict of {str : DataFrame} or None\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    xbrl = report.xbrl\n",
    "    if xbrl is None:\n",
    "        return None\n",
    "\n",
    "    # 재무제표 추출을 위한 함수\n",
    "    def get_fs():\n",
    "        data = xbrl.get_financial_statement(separate=separate)\n",
    "        return data[0] if data else None\n",
    "\n",
    "    def get_is():\n",
    "        data = xbrl.get_income_statement(separate=separate)\n",
    "        if data:\n",
    "            data = data[0] if len(data) > 1 else None\n",
    "        return data\n",
    "\n",
    "    def get_ci():\n",
    "        data = xbrl.get_income_statement(separate=separate)\n",
    "        if data:\n",
    "            data = data[1] if len(data) > 1 else data[0]\n",
    "        return data\n",
    "\n",
    "    def get_cf():\n",
    "        data = xbrl.get_cash_flows(separate=separate)\n",
    "        return data[0] if data else None\n",
    "\n",
    "    func_fs = {\n",
    "        'bs': get_fs,\n",
    "        'is': get_is,\n",
    "        'cis': get_ci,\n",
    "        'cf': get_cf,\n",
    "    }\n",
    "\n",
    "    # DataFrame 옵션\n",
    "    option = {\n",
    "        'label': 'Separate' if separate else 'Consolidated',\n",
    "        'lang': lang,\n",
    "        'show_abstract': show_abstract,\n",
    "        'show_class': show_class,\n",
    "        'show_depth': show_depth,\n",
    "        'show_concept': show_concept,\n",
    "        'separator': separator\n",
    "    }\n",
    "\n",
    "    statements = OrderedDict()\n",
    "    for tp in fs_tp:\n",
    "        statements[tp] = func_fs[tp]()\n",
    "        if statements[tp]:\n",
    "            statements[tp] = statements[tp].to_DataFrame(**option)\n",
    "    return statements\n",
    "\n",
    "\n",
    "def split_columns_concept_data(columns: pd.Index) -> Tuple[Optional[pd.Index], Optional[pd.Index]]:\n",
    "    regex = re.compile(r'\\d{8}')\n",
    "\n",
    "    concept_columns = []\n",
    "    data_columns = []\n",
    "    for column in columns:\n",
    "        df_column_date = regex.findall(column[0])\n",
    "        if len(df_column_date) == 0:\n",
    "            concept_columns.append(column)\n",
    "        else:\n",
    "            data_columns.append(column)\n",
    "    if len(concept_columns) > 0:\n",
    "        concept_columns = pd.MultiIndex.from_tuples(concept_columns)\n",
    "    else:\n",
    "        concept_columns = None\n",
    "    if len(data_columns) > 0:\n",
    "        data_columns = pd.MultiIndex.from_tuples(data_columns)\n",
    "    else:\n",
    "        data_columns = None\n",
    "    return concept_columns, data_columns\n",
    "\n",
    "\n",
    "def sorting_data_columns(columns: pd.Index) -> pd.Index:\n",
    "    def sorting(value):\n",
    "        if isinstance(value, str):\n",
    "            return value\n",
    "        else:\n",
    "            ret = [x for x in value]\n",
    "            return tuple(ret)\n",
    "\n",
    "    regex = re.compile(r'\\d{8}')\n",
    "    data_columns = []\n",
    "    for column in columns:\n",
    "        df_column_date = regex.findall(column[0])\n",
    "        data_columns.append([column, df_column_date])\n",
    "\n",
    "    data_columns.sort(key=lambda x: sorting(x[1]), reverse=True)\n",
    "    data_columns = [x[0] for x in data_columns]\n",
    "    data_columns = pd.MultiIndex.from_tuples(data_columns)\n",
    "    return data_columns\n",
    "\n",
    "\n",
    "def sorting_columns(statements: Dict[str, DataFrame]) -> Dict[str, DataFrame]:\n",
    "\n",
    "    for tp in statements:\n",
    "        df = statements[tp]\n",
    "        if df is None:\n",
    "            continue\n",
    "        concept_columns, data_columns = split_columns_concept_data(df.columns)\n",
    "        if data_columns is not None:\n",
    "            data_columns = sorting_data_columns(data_columns)\n",
    "\n",
    "        if concept_columns is not None and data_columns is not None:\n",
    "            ncolumns = concept_columns.tolist() + data_columns.tolist()\n",
    "            ncolumns = pd.MultiIndex.from_tuples(ncolumns)\n",
    "        else:\n",
    "            ncolumns = df.columns\n",
    "\n",
    "        statements[tp] = statements[tp][ncolumns]\n",
    "    return statements\n",
    "\n",
    "\n",
    "def drop_empty_columns(df: Dict[str, DataFrame], label_df: bool = False) -> Dict[str, DataFrame]:\n",
    "\n",
    "    for tp in df:\n",
    "        df_tp = df[tp]\n",
    "        if df_tp is None:\n",
    "            continue\n",
    "\n",
    "        if label_df:\n",
    "            none_columns = df_tp[df_tp != u''].isnull().all()\n",
    "        else:\n",
    "            none_columns = df_tp.isnull().all()\n",
    "\n",
    "        columns = []\n",
    "        for key, value in none_columns.items():\n",
    "            if value is not True:\n",
    "                columns.append(key)\n",
    "        # convert list to numpy array\n",
    "        columns = np.array(columns, dtype=object)\n",
    "        df[tp] = df_tp[columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def analyze_report(report: Report,\n",
    "                   fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'),\n",
    "                   separate: bool = False,\n",
    "                   lang: str = 'ko',\n",
    "                   separator: bool = True,\n",
    "                   dataset: str = 'xbrl') -> Union[Dict[str, Optional[DataFrame]], None]:\n",
    "    # 2012년 이후 데이터만 XBRL 데이터 추출\n",
    "    year = int(report.rcept_dt[:4])\n",
    "    if year > 2011 and dataset == 'xbrl':\n",
    "        xbrl = report.xbrl\n",
    "    else:\n",
    "        xbrl = None\n",
    "\n",
    "    # XBRL File check\n",
    "    if xbrl is not None:\n",
    "        if separate is False and not xbrl.exist_consolidated():\n",
    "            raise NotFoundConsolidated('Could not find consolidated financial statements')\n",
    "        fs_df = analyze_xbrl(report, fs_tp=fs_tp, separate=separate, lang=lang,\n",
    "                             show_abstract=False, show_class=True, show_depth=10,\n",
    "                             show_concept=True, separator=separator)\n",
    "    else:\n",
    "        fs_df = analyze_html(report, fs_tp=fs_tp, separate=separate, lang=lang)\n",
    "\n",
    "    return fs_df\n",
    "\n",
    "\n",
    "def search_annual_report(corp_code: str,\n",
    "                         bgn_de: str,\n",
    "                         end_de: str = None,\n",
    "                         separate: bool = False):\n",
    "\n",
    "    reports = []\n",
    "    try:\n",
    "        # 사업보고서 검색(최종보고서)\n",
    "        reports = search_filings(corp_code=corp_code, bgn_de=bgn_de, end_de=end_de,\n",
    "                                 pblntf_detail_ty='A001', page_count=100, last_reprt_at='Y')\n",
    "    except NoDataReceived:\n",
    "        # 감사보고서 검색\n",
    "        if separate:\n",
    "            pblntf_detail_ty = 'F001'\n",
    "        else:\n",
    "            pblntf_detail_ty = 'F002'\n",
    "        reports = search_filings(corp_code=corp_code, bgn_de=bgn_de, end_de=end_de,\n",
    "                                 pblntf_detail_ty=pblntf_detail_ty, page_count=100, last_reprt_at='Y')\n",
    "    finally:\n",
    "        if len(reports) == 0:\n",
    "            raise RuntimeError('Could not find an annual report')\n",
    "        return reports\n",
    "\n",
    "\n",
    "def extract(corp_code: str,\n",
    "            bgn_de: str,\n",
    "            end_de: str = None,\n",
    "            fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'),\n",
    "            separate: bool = False,\n",
    "            report_tp: Union[str, List[str]] = 'annual',\n",
    "            lang: str = 'ko',\n",
    "            separator: bool = True,\n",
    "            dataset: str = 'xbrl') -> FinancialStatement:\n",
    "    \"\"\"\n",
    "    재무제표 검색\n",
    "    Parameters\n",
    "    ----------\n",
    "    corp_code: str\n",
    "        공시대상회사의 고유번호(8자리)\n",
    "    bgn_de: str\n",
    "        검색 시작일자(YYYYMMDD)\n",
    "    end_de: str, optional\n",
    "        검색 종료일자(YYYYMMDD)\n",
    "    fs_tp: tuple of str, optional\n",
    "        'bs' 재무상태표, 'is' 손익계산서, 'cis' 포괄손익계산서, 'cf' 현금흐름표\n",
    "    separate: bool, optional\n",
    "        개별재무제표 여부\n",
    "    report_tp: str or list, optional\n",
    "        str: 'annual' 연간, 'half' 연간 + 반기, 'quarter' 연간 + 반기 + 분기\n",
    "        list: ['annual'] : 연간, ['half']: 반기, ['quarter'] 분기, ['annual', 'half']: 연간 + 반기\n",
    "              ['annual', 'quarter']: 연간 + 분기, ['half', 'quarter']:  반기 + 분기, ['annual', 'half', 'quarter']: 연간 + 반기 + 분기\n",
    "    lang: str, optional\n",
    "        'ko' 한글, 'en' 영문\n",
    "    separator: bool, optional\n",
    "        1000단위 구분자 표시 여부\n",
    "    dataset: str, optional\n",
    "        'xbrl': xbrl 파일 우선 데이터 추출, 'web': web page 우선 데이터 추출(default: 'xbrl')\n",
    "    Returns\n",
    "    -------\n",
    "    FinancialStatement\n",
    "        제무제표 검색 결과\n",
    "    \"\"\"\n",
    "    if is_notebook():\n",
    "        from tqdm import tqdm_notebook as tqdm\n",
    "    else:\n",
    "        from tqdm import tqdm\n",
    "\n",
    "    if dataset not in ['xbrl', 'web']:\n",
    "        raise ValueError('invalid dataset type: only xbrl or web are allowed')\n",
    "\n",
    "    all_report_tp = ('annual', 'half', 'quarter')\n",
    "    all_report_name = ('Annual', 'Semiannual', 'Quarterly')\n",
    "    all_pblntf_detail_ty = ('A001', 'A002', 'A003')\n",
    "\n",
    "    def check_report_tp(req_tp, tp):\n",
    "        if isinstance(req_tp, str):\n",
    "            index = all_report_tp.index(req_tp) + 1\n",
    "            if tp in all_report_tp[:index]:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        elif isinstance(req_tp, list) and tp in req_tp:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Spinner disable\n",
    "    import dart_fss as dart\n",
    "    dart.utils.spinner.spinner_enable = False\n",
    "    statements = None\n",
    "    label_df = None\n",
    "    report = None\n",
    "    try:\n",
    "        for idx, tp in enumerate(all_report_tp):\n",
    "            if check_report_tp(report_tp, tp):\n",
    "                if tp == 'annual':\n",
    "                    reports = search_annual_report(corp_code=corp_code, bgn_de=bgn_de, end_de=end_de, separate=separate)\n",
    "                else:\n",
    "                    reports = search_filings(corp_code=corp_code, bgn_de=bgn_de, end_de=end_de,\n",
    "                                             pblntf_detail_ty=all_pblntf_detail_ty[idx], page_count=100, last_reprt_at='Y')\n",
    "                length = len(reports)\n",
    "                for _ in tqdm(range(length), desc='{} reports'.format(all_report_name[idx]), unit='report'):\n",
    "                    report = reports.pop(0)\n",
    "                    print(report)\n",
    "                    if statements is None:\n",
    "                        statements = analyze_report(report=report,\n",
    "                                                    fs_tp=fs_tp,\n",
    "                                                    separate=separate,\n",
    "                                                    lang=lang,\n",
    "                                                    separator=separator)\n",
    "                        if statements is None:\n",
    "                            warnings_text = 'Unable to extract financial statements: {}.'.format(report.to_dict())\n",
    "                            warnings.warn(warnings_text, RuntimeWarning)\n",
    "                        else:\n",
    "                            if separate is False and all([statements[tp] is None for tp in statements]):\n",
    "                                raise NotFoundConsolidated('Could not find consolidated financial statements')\n",
    "                            # initialize label dictionary\n",
    "                            label_df = init_label(statements, fs_tp=fs_tp)\n",
    "\n",
    "                    else:\n",
    "                        nstatements = analyze_report(report=report,\n",
    "                                                     fs_tp=fs_tp,\n",
    "                                                     separate=separate,\n",
    "                                                     lang=lang,\n",
    "                                                     separator=separator,\n",
    "                                                     dataset=dataset)\n",
    "                        if nstatements is None:\n",
    "                            warnings_text = 'Unable to extract financial statements: {}.'.format(report.to_dict())\n",
    "                            warnings.warn(warnings_text, RuntimeWarning)\n",
    "                        else:\n",
    "                            statements, label_df = merge_fs(statements, nstatements, fs_tp=fs_tp, label_df=label_df)\n",
    "\n",
    "        # Spinner enable\n",
    "        dart.utils.spinner.spinner_enable = True\n",
    "        if separate is False and (statements is None or all([statements[tp] is None for tp in statements])):\n",
    "            raise NotFoundConsolidated('Could not find consolidated financial statements')\n",
    "\n",
    "        statements = drop_empty_columns(statements)\n",
    "        label_df = drop_empty_columns(label_df)\n",
    "\n",
    "        statements = sorting_columns(statements)\n",
    "        label_df = sorting_columns(label_df)\n",
    "\n",
    "        info = {\n",
    "            'corp_code': corp_code,\n",
    "            'bgn_de': bgn_de,\n",
    "            'end_de': end_de,\n",
    "            'separate': separate,\n",
    "            'report_tp': report_tp,\n",
    "            'lang': lang,\n",
    "            'separator': separator\n",
    "        }\n",
    "        return FinancialStatement(statements, label_df, info)\n",
    "    except Exception as e:\n",
    "        if report is not None:\n",
    "            msg = 'An error occurred while fetching or analyzing {}.'.format(report.to_dict())\n",
    "        else:\n",
    "            msg = 'Unexpected Error'\n",
    "        e.args = (*e.args, msg, )\n",
    "        raise e\n",
    "    finally:\n",
    "        dart.utils.spinner.spinner_enable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "forward-hacker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:21:41.757740Z",
     "start_time": "2021-05-16T04:21:41.712705Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_report(report: Report,\n",
    "                   fs_tp: Tuple[str] = ('bs', 'is', 'cis', 'cf'),\n",
    "                   separate: bool = False,\n",
    "                   lang: str = 'ko',\n",
    "                   separator: bool = True,\n",
    "                   dataset: str = 'xbrl') -> Union[Dict[str, Optional[DataFrame]], None]:\n",
    "    # 2012년 이후 데이터만 XBRL 데이터 추출\n",
    "    year = int(report.rcept_dt[:4])\n",
    "    if year > 2011 and dataset == 'xbrl':\n",
    "        xbrl = report.xbrl\n",
    "        print(xbrl)\n",
    "#         if xbrl == None:\n",
    "#             pass\n",
    "#         elif xbrl.exist_consolidated() == 0:\n",
    "#             separate = True\n",
    "#             xbrl = report.xbrl\n",
    "    else:\n",
    "        xbrl = None\n",
    "\n",
    "    # XBRL File check\n",
    "    # XBRL 에 값이 있음.\n",
    "    if xbrl is not None:\n",
    "        print('a')\n",
    "        # 연결인데, 연결값이 없는 경우.\n",
    "        if separate is False and not xbrl.exist_consolidated():\n",
    "            separate=True\n",
    "#             raise NotFoundConsolidated('Could not find consolidated financial statements')\n",
    "        fs_df = analyze_xbrl(report, fs_tp=fs_tp, separate=separate, lang=lang,\n",
    "                             show_abstract=False, show_class=True, show_depth=10,\n",
    "                             show_concept=True, separator=separator)\n",
    "    else:\n",
    "        print('b')\n",
    "        separate=True\n",
    "        fs_df = analyze_html(report, fs_tp=fs_tp, separate=separate, lang=lang)\n",
    "        \n",
    "    return fs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coastal-feeding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:19:36.769828Z",
     "start_time": "2021-05-16T04:19:36.760824Z"
    }
   },
   "outputs": [],
   "source": [
    "def stock_code_reset(stock_code):\n",
    "    corp_code = corp_df[corp_df['stock_code'] == stock_code].iloc[0, 0]\n",
    "    return corp_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "funny-optimization",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:19:54.476429Z",
     "start_time": "2021-05-16T04:19:38.487667Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('Raw/Corpcode/corp_num/CORPCODE.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "corp_df = pd.DataFrame(columns=['corp_code','corp_name','stock_code','modify_date'])\n",
    "for company in root.iter('list'):\n",
    "    stock_code = company.findtext('stock_code')\n",
    "    stock_code = stock_code.strip()\n",
    "    if stock_code:\n",
    "        company_dict = {\n",
    "            'corp_code':company.findtext('corp_code'),\n",
    "            'corp_name':company.findtext('corp_name'),\n",
    "            'stock_code':company.findtext('stock_code'),\n",
    "            'modify_date':company.findtext('modify_date')\n",
    "        }\n",
    "        corp_df = corp_df.append(company_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "southeast-yesterday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:19:54.506957Z",
     "start_time": "2021-05-16T04:19:54.480432Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 경고메시지 무시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-society",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:09.313968Z",
     "start_time": "2021-05-16T04:19:55.925274Z"
    }
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "stock_list_kospi = fdr.StockListing('KOSPI')['Symbol'].to_list()\n",
    "stock_list_kosdaq = fdr.StockListing('KOSDAQ')['Symbol'].to_list()\n",
    "stock_df_del = fdr.StockListing('KRX-DELISTING')\n",
    "stock_list_del = stock_df_del[(stock_df_del['Market'] == \"KOSPI\") | (stock_df_del['Market'] == \"KOSDAQ\")]['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recorded-traveler",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:14.134958Z",
     "start_time": "2021-05-16T04:20:14.103930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1498"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# stock_code_list 정제하기 (우선주, 리츠, 옵션) -> 6자리 숫자만, 맨 앞자리에 0 들어가는 것만\n",
    "stock_code_list = []\n",
    "for stock_code in stock_list_kosdaq:\n",
    "    stock_code = re.findall(\"\\d+\", stock_code)[0] # 숫자만 추출한 뒤 첫번째 것만 사용\n",
    "    if (stock_code[-1] == '0') and (len(stock_code) == 6):\n",
    "        stock_code_list.append(stock_code)\n",
    "len(stock_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entire-particular",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:36.171402Z",
     "start_time": "2021-05-16T04:20:20.399333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c615ed92ad448ec8765c7311071d96e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8a4a8fef8f44398ab6897e895c9bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0723e3ca0d4468a83ff4ebe6c0749e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corp_list = dart.get_corp_list()\n",
    "none_list=[]\n",
    "for stock_code in stock_code_list:\n",
    "    data = corp_list.find_by_stock_code(stock_code)\n",
    "    if data == None:\n",
    "        none_list.append(stock_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "neural-chicken",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:37.911831Z",
     "start_time": "2021-05-16T04:20:37.877829Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(title):\n",
    "    return title[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "black-associate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:43.272583Z",
     "start_time": "2021-05-16T04:20:43.114538Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_path = './Raw/fssdata_kosdaq/'\n",
    "files_list_kosdaq1 = os.listdir(data_path)\n",
    "data_path = './Raw/fssdata_temp1/'\n",
    "files_list_kosdaq2 = os.listdir(data_path)\n",
    "files_list_kosdaq1 = list(map(f,files_list_kosdaq1))\n",
    "files_list_kosdaq2 = list(map(f,files_list_kosdaq2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ultimate-passport",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:43.824033Z",
     "start_time": "2021-05-16T04:20:43.762509Z"
    }
   },
   "outputs": [],
   "source": [
    "for stock in none_list+files_list_kosdaq1+files_list_kosdaq2:\n",
    "    stock_code_list.remove(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "plain-blink",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:20:45.492479Z",
     "start_time": "2021-05-16T04:20:45.450958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stock_code_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "concerned-gamma",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:24:39.334615Z",
     "start_time": "2021-05-16T04:24:39.220571Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_code = stock_code_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pediatric-needle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:24:41.244651Z",
     "start_time": "2021-05-16T04:24:41.149586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'367340'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fossil-answer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:24:48.859015Z",
     "start_time": "2021-05-16T04:24:43.246961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26f6dd454824bd18f0241adb365fbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Annual reports:   0%|          | 0/1 [00:00<?, ?report/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'corp_cls': 'K',\n",
      " 'corp_code': '01505450',\n",
      " 'corp_name': 'DB금융스팩8호',\n",
      " 'flr_nm': 'DB금융스팩8호',\n",
      " 'rcept_dt': '20210318',\n",
      " 'rcp_no': '20210318000524',\n",
      " 'report_nm': '사업보고서 (2020.12)',\n",
      " 'rm': '',\n",
      " 'stock_code': '367340'}\n",
      "None\n",
      "b\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-16331738b645>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorp_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstock_code_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbgn_de\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'20130101'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_de\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'20210415'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreport_tp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'quarter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-4d27294f4060>\u001b[0m in \u001b[0;36mextract\u001b[1;34m(corp_code, bgn_de, end_de, fs_tp, separate, report_tp, lang, separator, dataset)\u001b[0m\n\u001b[0;32m   1236\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mstatements\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1238\u001b[1;33m                         statements = analyze_report(report=report,\n\u001b[0m\u001b[0;32m   1239\u001b[0m                                                     \u001b[0mfs_tp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_tp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                                                     \u001b[0mseparate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseparate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-fab91b732b6d>\u001b[0m in \u001b[0;36manalyze_report\u001b[1;34m(report, fs_tp, separate, lang, separator, dataset)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mseparate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mfs_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_tp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_tp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseparate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfs_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-4d27294f4060>\u001b[0m in \u001b[0;36manalyze_html\u001b[1;34m(report, fs_tp, lang, separate)\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'includes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' AND 연결'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m     \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreport_find_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_tp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;31m# 검색결과가 없을시 재검색, 검색 키워드 변경\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-4d27294f4060>\u001b[0m in \u001b[0;36mreport_find_all\u001b[1;34m(report, query, fs_tp, separate)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[0mfs_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[0msearched_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m     \u001b[0msearched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msearched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36mfind_all\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36mattached_reports\u001b[1;34m()\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mattached_reports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattached_reports\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdeterminant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rpt_nm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattached_reports\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mattached_reports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattached_reports\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdeterminant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rpt_nm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattached_reports\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36mfind_all\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         return [\n\u001b[1;32m--> 522\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpages\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdeterminant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m         ]\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36mpages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \"\"\"\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pages\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36mextract_pages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'TreeNode\\({(.*?)}\\)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\filings\\reports.py\u001b[0m in \u001b[0;36m_get_report\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdcm_no\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mpayload\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dcmNo'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdcm_no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_REPORT_URL_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_DART_URL_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\utils\\request.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, payload, referer, stream, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mResponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreferer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreferer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     def post(self, url: str,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38_64\\lib\\site-packages\\dart_fss\\utils\\request.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, url, method, payload, referer, stream, timeout)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprepped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelay\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fs = extract(corp_code = stock_code_reset(stock_code), bgn_de='20130101',end_de='20210415',report_tp='quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "flexible-delaware",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T01:29:54.612468Z",
     "start_time": "2021-05-16T01:29:53.654386Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reports' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-bbe3a94507a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'reports' is not defined"
     ]
    }
   ],
   "source": [
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "stopped-logistics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T14:05:43.190096Z",
     "start_time": "2021-05-15T14:05:42.109373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Raw/Temp\\\\367340.xlsx'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.save(filename = '{}.xlsx'.format(stock_code), path=\"Raw/Temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "appointed-alarm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T13:08:53.850182Z",
     "start_time": "2021-05-15T13:08:52.871593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style scoped>\n",
       "        .dart-table tbody tr th {\n",
       "            vertical-align: top;\n",
       "            text-overflow: ellipsis;\n",
       "        }\n",
       "        .dart-table thead th {\n",
       "            text-align: right;\n",
       "            text-overflow: ellipsis;\n",
       "        }\n",
       "    </style>\n",
       "    <table border=\"1\" class=\"dart-table\"><thead><tr style=\"text-align: right;\"><th>Label</th><th>Data</th></tr></thead><tbody><tr><th>corp_code</th><td>00915508</td></tr><tr><th>bgn_de</th><td>20130101</td></tr><tr><th>end_de</th><td>20210415</td></tr><tr><th>separate</th><td>False</td></tr><tr><th>report_tp</th><td>quarter</td></tr><tr><th>lang</th><td>ko</td></tr><tr><th>separator</th><td>True</td></tr><tr><th>financial statement</th><td><table style=\"width:100%\"><thead><tr><th width=\"20\">No.</th><th>title</th></tr></thead><tbody><tr><th width=\"20\">0</th><td>[D210005] Statement of financial position, current/non-current - Separate financial statements (Unit: KRW)</td></tr><tr><th width=\"20\">1</th><td>is is None</td></tr><tr><th width=\"20\">2</th><td>[D431415] Statement of comprehensive income, by function of expense - Separate financial statements (Unit: KRW)</td></tr><tr><th width=\"20\">3</th><td>[D520005] Statement of cash flows, indirect method - Separate financial statements (Unit: KRW)</td></tr></tbody></table></td></tr></tbody></table>"
      ],
      "text/plain": [
       "{'bgn_de': '20130101',\n",
       " 'corp_code': '00915508',\n",
       " 'end_de': '20210415',\n",
       " 'financial statement': [{'title': '[D210005] Statement of financial position, '\n",
       "                                   'current/non-current - Separate financial '\n",
       "                                   'statements (Unit: KRW)'},\n",
       "                         {'title': 'is is None'},\n",
       "                         {'title': '[D431415] Statement of comprehensive '\n",
       "                                   'income, by function of expense - Separate '\n",
       "                                   'financial statements (Unit: KRW)'},\n",
       "                         {'title': '[D520005] Statement of cash flows, '\n",
       "                                   'indirect method - Separate financial '\n",
       "                                   'statements (Unit: KRW)'}],\n",
       " 'lang': 'ko',\n",
       " 'report_tp': 'quarter',\n",
       " 'separate': False,\n",
       " 'separator': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "approved-symbol",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:26:21.355948Z",
     "start_time": "2021-05-16T04:26:20.208618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': '000',\n",
       " 'message': '정상',\n",
       " 'page_no': 1,\n",
       " 'page_count': 100,\n",
       " 'total_count': 4,\n",
       " 'total_page': 1,\n",
       " 'list': [{'corp_code': '00556712',\n",
       "   'corp_name': '힘스',\n",
       "   'stock_code': '238490',\n",
       "   'corp_cls': 'K',\n",
       "   'report_nm': '[기재정정]반기보고서 (2020.06)',\n",
       "   'rcept_no': '20200907000001',\n",
       "   'flr_nm': '힘스',\n",
       "   'rcept_dt': '20200907',\n",
       "   'rm': ''},\n",
       "  {'corp_code': '00556712',\n",
       "   'corp_name': '힘스',\n",
       "   'stock_code': '238490',\n",
       "   'corp_cls': 'K',\n",
       "   'report_nm': '반기보고서 (2019.06)',\n",
       "   'rcept_no': '20190814000045',\n",
       "   'flr_nm': '힘스',\n",
       "   'rcept_dt': '20190814',\n",
       "   'rm': ''},\n",
       "  {'corp_code': '00556712',\n",
       "   'corp_name': '힘스',\n",
       "   'stock_code': '238490',\n",
       "   'corp_cls': 'K',\n",
       "   'report_nm': '반기보고서 (2018.06)',\n",
       "   'rcept_no': '20180814002954',\n",
       "   'flr_nm': '힘스',\n",
       "   'rcept_dt': '20180814',\n",
       "   'rm': ''},\n",
       "  {'corp_code': '00556712',\n",
       "   'corp_name': '힘스',\n",
       "   'stock_code': '238490',\n",
       "   'corp_cls': 'K',\n",
       "   'report_nm': '반기보고서 (2017.06)',\n",
       "   'rcept_no': '20170811000537',\n",
       "   'flr_nm': '힘스',\n",
       "   'rcept_dt': '20170811',\n",
       "   'rm': ''}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_code='238490'\n",
    "a = search_filings(corp_code = stock_code_reset(stock_code), bgn_de='20130101',end_de='20210415',pblntf_detail_ty='A002', page_count=100, last_reprt_at='Y')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "further-meter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:26:30.594219Z",
     "start_time": "2021-05-16T04:26:30.495680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "unexpected-consultation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:23:36.433689Z",
     "start_time": "2021-05-16T04:23:34.139357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style scoped>\n",
       "        .dart-table tbody tr th {\n",
       "            vertical-align: top;\n",
       "            text-overflow: ellipsis;\n",
       "        }\n",
       "        .dart-table thead th {\n",
       "            text-align: right;\n",
       "            text-overflow: ellipsis;\n",
       "        }\n",
       "    </style>\n",
       "    <table border=\"1\" class=\"dart-table\"><thead><tr style=\"text-align: right;\"><th>Label</th><th>Data</th></tr></thead><tbody><tr><th>rcp_no</th><td>20210316000194</td></tr><tr><th>corp_code</th><td>00556712</td></tr><tr><th>corp_name</th><td>힘스</td></tr><tr><th>stock_code</th><td>238490</td></tr><tr><th>corp_cls</th><td>K</td></tr><tr><th>report_nm</th><td>사업보고서 (2020.12)</td></tr><tr><th>flr_nm</th><td>힘스</td></tr><tr><th>rcept_dt</th><td>20210316</td></tr><tr><th>rm</th><td>연</td></tr><tr><th>xbrl</th><td>[힘스]사업보고서_IFRS(원문XBRL)(2021.03.16).zip</td></tr><tr><th>attached_reports</th><td><table style=\"width:100%\"><thead><tr><th width=\"20\">No.</th><th>rpt_nm</th></tr></thead><tbody><tr><th width=\"20\">0</th><td>2021.03.16 감사보고서</td></tr><tr><th width=\"20\">1</th><td>2021.03.16 감사의감사보고서</td></tr><tr><th width=\"20\">2</th><td>2021.03.16 내부감시장치에대한감사의의견서</td></tr><tr><th width=\"20\">3</th><td>2021.03.16 내부회계관리제도운영보고서</td></tr><tr><th width=\"20\">4</th><td>2021.03.16 연결감사보고서</td></tr><tr><th width=\"20\">5</th><td>2021.03.16 영업보고서</td></tr><tr><th width=\"20\">6</th><td>2021.03.16 정관</td></tr></tbody></table></td></tr><tr><th>attached_files</th><td><table style=\"width:100%\"><thead><tr><th width=\"20\">No.</th><th>filename</th></tr></thead><tbody><tr><th width=\"20\">0</th><td>[힘스]사업보고서(2021.03.16).pdf</td></tr><tr><th width=\"20\">1</th><td>emb00003958620f.jpg</td></tr><tr><th width=\"20\">2</th><td>emb000039586210.jpg</td></tr><tr><th width=\"20\">3</th><td>emb00003a3065e7.jpg</td></tr><tr><th width=\"20\">4</th><td>emb000045e81ce5.jpg</td></tr><tr><th width=\"20\">5</th><td>flexible점유율.jpg</td></tr><tr><th width=\"20\">6</th><td>lcd,oled 모듈구조 비교.jpg</td></tr><tr><th width=\"20\">7</th><td>대표이사등의확인서.jpg</td></tr><tr><th width=\"20\">8</th><td>디스플레이 전후방 산업.jpg</td></tr><tr><th width=\"20\">9</th><td>디스플레이시장전망.jpg</td></tr><tr><th width=\"20\">10</th><td>스마트폰 oled 플렉시블 패널 성장.jpg</td></tr><tr><th width=\"20\">11</th><td>스마트폰 패널 사용 트렌드 변화 예상.jpg</td></tr><tr><th width=\"20\">12</th><td>슬라이드1.jpg</td></tr><tr><th width=\"20\">13</th><td>연구소조직.jpg</td></tr><tr><th width=\"20\">14</th><td>자료 , 하이투자증권(2020.06).jpg</td></tr><tr><th width=\"20\">15</th><td>자료 하이투자증권(2020.6).jpg</td></tr><tr><th width=\"20\">16</th><td>자료, 하이투자증권(2020.06).jpg</td></tr><tr><th width=\"20\">17</th><td>자료, 한국디스플레이혐회, ihs(2017,2분기).jpg</td></tr><tr><th width=\"20\">18</th><td>자료. 하이투자증권(2020.06).jpg</td></tr><tr><th width=\"20\">19</th><td>중국법인 외부감사인.jpg</td></tr><tr><th width=\"20\">20</th><td>중소기업기준검토표_1.jpg</td></tr><tr><th width=\"20\">21</th><td>중소기업기준검토표_2.jpg</td></tr><tr><th width=\"20\">22</th><td>플렉시블 디스플레이 종류.jpg</td></tr><tr><th width=\"20\">23</th><td>[힘스]사업보고서_재무제표(2021.03.16)_ko.xls</td></tr><tr><th width=\"20\">24</th><td>[힘스]사업보고서_IFRS(원문XBRL)(2021.03.16).zip</td></tr></tbody></table></td></tr><tr><th>pages</th><td><table style=\"width:100%\"><thead><tr><th width=\"20\">No.</th><th>title</th><th>ele_id</th></tr></thead><tbody><tr><th width=\"20\">0</th><td>전체</td><td>0</td></tr><tr><th width=\"20\">1</th><td>사업보고서</td><td>1</td></tr><tr><th width=\"20\">2</th><td>【대표이사등의확인】</td><td>2</td></tr><tr><th width=\"20\">3</th><td>I.회사의개요</td><td>3</td></tr><tr><th width=\"20\">4</th><td>1.회사의개요</td><td>4</td></tr><tr><th width=\"20\">5</th><td>2.회사의연혁</td><td>5</td></tr><tr><th width=\"20\">6</th><td>3.자본금변동사항</td><td>6</td></tr><tr><th width=\"20\">7</th><td>4.주식의총수등</td><td>7</td></tr><tr><th width=\"20\">8</th><td>5.의결권현황</td><td>8</td></tr><tr><th width=\"20\">9</th><td>6.배당에관한사항등</td><td>9</td></tr><tr><th width=\"20\">10</th><td>7.정관에관한사항</td><td>10</td></tr><tr><th width=\"20\">11</th><td>II.사업의내용</td><td>11</td></tr><tr><th width=\"20\">12</th><td>III.재무에관한사항</td><td>12</td></tr><tr><th width=\"20\">13</th><td>1.요약재무정보</td><td>13</td></tr><tr><th width=\"20\">14</th><td>2.연결재무제표</td><td>14</td></tr><tr><th width=\"20\">15</th><td>3.연결재무제표주석</td><td>15</td></tr><tr><th width=\"20\">16</th><td>4.재무제표</td><td>16</td></tr><tr><th width=\"20\">17</th><td>5.재무제표주석</td><td>17</td></tr><tr><th width=\"20\">18</th><td>6.기타재무에관한사항</td><td>18</td></tr><tr><th width=\"20\">19</th><td>IV.이사의경영진단및분석의견</td><td>19</td></tr><tr><th width=\"20\">20</th><td>V.감사인의감사의견등</td><td>20</td></tr><tr><th width=\"20\">21</th><td>VI.이사회등회사의기관에관한사항</td><td>21</td></tr><tr><th width=\"20\">22</th><td>1.이사회에관한사항</td><td>22</td></tr><tr><th width=\"20\">23</th><td>2.감사제도에관한사항</td><td>23</td></tr><tr><th width=\"20\">24</th><td>3.주주의의결권행사에관한사항</td><td>24</td></tr><tr><th width=\"20\">25</th><td>VII.주주에관한사항</td><td>25</td></tr><tr><th width=\"20\">26</th><td>VIII.임원및직원등에관한사항</td><td>26</td></tr><tr><th width=\"20\">27</th><td>1.임원및직원등의현황</td><td>27</td></tr><tr><th width=\"20\">28</th><td>2.임원의보수등</td><td>28</td></tr><tr><th width=\"20\">29</th><td>IX.계열회사등에관한사항</td><td>29</td></tr><tr><th width=\"20\">30</th><td>X.이해관계자와의거래내용</td><td>30</td></tr><tr><th width=\"20\">31</th><td>XI.그밖에투자자보호를위하여필요한사항</td><td>31</td></tr><tr><th width=\"20\">32</th><td>【전문가의확인】</td><td>32</td></tr><tr><th width=\"20\">33</th><td>1.전문가의확인</td><td>33</td></tr><tr><th width=\"20\">34</th><td>2.전문가와의이해관계</td><td>34</td></tr></tbody></table></td></tr></tbody></table>"
      ],
      "text/plain": [
       "{'corp_cls': 'K',\n",
       " 'corp_code': '00556712',\n",
       " 'corp_name': '힘스',\n",
       " 'flr_nm': '힘스',\n",
       " 'rcept_dt': '20210316',\n",
       " 'rcp_no': '20210316000194',\n",
       " 'report_nm': '사업보고서 (2020.12)',\n",
       " 'rm': '연',\n",
       " 'stock_code': '238490'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "apart-nickel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T04:25:40.748439Z",
     "start_time": "2021-05-16T04:25:40.644903Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "from dart_fss.auth import get_api_key\n",
    "from dart_fss.utils import request, str_upper\n",
    "from dart_fss.errors import check_status\n",
    "str_or_list = Union[str, List[str]]\n",
    "def search_filings(corp_code: str = None,\n",
    "                   bgn_de: str = None,\n",
    "                   end_de: str = None,\n",
    "                   last_reprt_at: str = 'N',\n",
    "                   pblntf_ty: str_or_list = None,\n",
    "                   pblntf_detail_ty: str_or_list = None,\n",
    "                   corp_cls: str = None,\n",
    "                   sort: str = 'date',\n",
    "                   sort_mth: str = 'desc',\n",
    "                   page_no: int = 1,\n",
    "                   page_count: int = 10):\n",
    "    \"\"\" 공시보고서 검색\n",
    "    Parameters\n",
    "    ----------\n",
    "    corp_code: str, optional\n",
    "        공시대상회사의 고유번호(8자리), 고유번호(corp_code)가 없는 경우 검색기간은 3개월로 제한\n",
    "    bgn_de: str, optional\n",
    "        검색시작 접수일자(YYYYMMDD), 없으면 종료일(end_de)\n",
    "    end_de: str, optional\n",
    "        검색종료 접수일자(YYYYMMDD), 없으면 당일\n",
    "    last_reprt_at: str, optional\n",
    "        최종보고서만 검색여부(Y or N), default : N\n",
    "    pblntf_ty: str, optional\n",
    "        공시유형\n",
    "    pblntf_detail_ty: str, optional\n",
    "        공시상세유형\n",
    "    corp_cls: str, optional\n",
    "        법인구분 : Y(유가), K(코스닥), N(코넥스), E(기타), 없으면 전체조회\n",
    "    sort: str, optional\n",
    "        정렬, {접수일자: date, 회사명: crp, 고서명: rpt}\n",
    "    sort_mth: str, optional\n",
    "        오름차순(asc), 내림차순(desc), default : desc\n",
    "    page_no: int, optional\n",
    "        페이지 번호(1~n) default : 1\n",
    "    page_count: int, optional\n",
    "        페이지당 건수(1~100) 기본값 : 10, default : 100\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Response data\n",
    "    \"\"\"\n",
    "    url = 'https://opendart.fss.or.kr/api/list.json'\n",
    "\n",
    "    api_key = get_api_key()\n",
    "\n",
    "    last_reprt_at = str_upper(last_reprt_at)\n",
    "    pblntf_ty = str_upper(pblntf_ty)\n",
    "    pblntf_detail_ty = str_upper(pblntf_detail_ty)\n",
    "\n",
    "    payload = {\n",
    "        'crtfc_key': api_key,\n",
    "        'corp_code': corp_code,\n",
    "        'bgn_de': bgn_de,\n",
    "        'end_de': end_de,\n",
    "        'last_reprt_at': last_reprt_at,\n",
    "        'pblntf_ty': pblntf_ty,\n",
    "        'pblntf_detail_ty': pblntf_detail_ty,\n",
    "        'corp_cls': corp_cls,\n",
    "        'sort': sort,\n",
    "        'sort_mth': sort_mth,\n",
    "        'page_no': page_no,\n",
    "        'page_count': page_count\n",
    "    }\n",
    "\n",
    "    resp = request.get(url=url, payload=payload)\n",
    "    dataset = resp.json()\n",
    "\n",
    "    # Check Error\n",
    "#     check_status(**dataset)\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_64",
   "language": "python",
   "name": "py38_64"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
